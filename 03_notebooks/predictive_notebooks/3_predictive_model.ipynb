{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24697b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: imports & paths ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = Path(\"../../01_data\") / \"predictive_model\"\n",
    "CORPUS_PATH = DATA_DIR / \"df_auto_corpus_area_tech.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: load + basic filters (paper/patent + date) ===\n",
    "\n",
    "df = pd.read_parquet(CORPUS_PATH)\n",
    "\n",
    "# sadece paper + patent\n",
    "df = df[df[\"source_type\"].isin([\"paper\", \"patent\"])].copy()\n",
    "\n",
    "# year / month NA'leri at\n",
    "df = df.dropna(subset=[\"year\", \"month\"])\n",
    "\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "df[\"month\"] = df[\"month\"].astype(int)\n",
    "\n",
    "# ayın ilk günü olacak şekilde tarih\n",
    "df[\"date\"] = pd.to_datetime(\n",
    "    dict(year=df[\"year\"], month=df[\"month\"], day=1)\n",
    ")\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779390a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: area-tech-date level time series (df_ts) ===\n",
    "\n",
    "g = df.groupby(\n",
    "    [\"auto_focus_area\", \"auto_tech_cluster\", \"date\", \"source_type\"]\n",
    ").size().reset_index(name=\"n\")\n",
    "\n",
    "pivot = g.pivot_table(\n",
    "    index=[\"auto_focus_area\", \"auto_tech_cluster\", \"date\"],\n",
    "    columns=\"source_type\",\n",
    "    values=\"n\",\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "pivot.columns.name = None\n",
    "\n",
    "for col in [\"paper\", \"patent\"]:\n",
    "    if col not in pivot.columns:\n",
    "        pivot[col] = 0\n",
    "\n",
    "pivot[\"n_total\"] = pivot[\"paper\"] + pivot[\"patent\"]\n",
    "pivot[\"share_paper\"] = np.where(pivot[\"n_total\"] > 0, pivot[\"paper\"] / pivot[\"n_total\"], 0.0)\n",
    "pivot[\"share_patent\"] = np.where(pivot[\"n_total\"] > 0, pivot[\"patent\"] / pivot[\"n_total\"], 0.0)\n",
    "\n",
    "df_ts = pivot.copy()\n",
    "df_ts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: helper functions – prepare_time_series & linear_forecast ===\n",
    "\n",
    "def prepare_time_series(group_df: pd.DataFrame, value_col: str):\n",
    "    g = group_df.sort_values(\"date\")\n",
    "    g = g[[\"date\", value_col]].dropna()\n",
    "\n",
    "    if len(g) < 4:\n",
    "        return None, None\n",
    "\n",
    "    t = np.arange(len(g)).reshape(-1, 1)\n",
    "    y = g[value_col].values.astype(float)\n",
    "    return t, y\n",
    "\n",
    "\n",
    "def linear_forecast(group_df: pd.DataFrame, value_col: str, horizon: int = 12):\n",
    "    g = group_df.sort_values(\"date\")\n",
    "    t, y = prepare_time_series(g, value_col)\n",
    "    if t is None:\n",
    "        return g, None\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(t, y)\n",
    "\n",
    "    last_t = t[-1, 0]\n",
    "    future_t = np.arange(last_t + 1, last_t + 1 + horizon).reshape(-1, 1)\n",
    "    y_pred = model.predict(future_t)\n",
    "\n",
    "    last_date = g[\"date\"].max()\n",
    "    future_dates = pd.date_range(\n",
    "        start=last_date + pd.offsets.MonthBegin(1),\n",
    "        periods=horizon,\n",
    "        freq=\"MS\"\n",
    "    )\n",
    "\n",
    "    forecast_df = pd.DataFrame({\n",
    "        \"date\": future_dates,\n",
    "        f\"forecast_{value_col}\": y_pred\n",
    "    })\n",
    "\n",
    "    return g, forecast_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47267fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: logistic (S-curve) forecast ===\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def _logistic_fn(t, K, r, t0):\n",
    "    return K / (1.0 + np.exp(-r * (t - t0)))\n",
    "\n",
    "\n",
    "def logistic_forecast(group_df: pd.DataFrame,\n",
    "                      value_col: str,\n",
    "                      horizon: int = 12):\n",
    "    \"\"\"\n",
    "    value_col: 'n_total' veya 'share_patent' gibi kolonlar için\n",
    "    lojistik (S-curve) fit + forecast. Fit patlarsa linear_forecast'e düşer.\n",
    "    \"\"\"\n",
    "    g = group_df.sort_values(\"date\")\n",
    "    t, y = prepare_time_series(g, value_col)\n",
    "    if t is None:\n",
    "        return g, None\n",
    "\n",
    "    t = t.astype(float).ravel()\n",
    "\n",
    "    y_min, y_max = float(y.min()), float(y.max())\n",
    "    if y_max == y_min:\n",
    "        return linear_forecast(g, value_col, horizon=horizon)\n",
    "\n",
    "    y_norm = (y - y_min) / (y_max - y_min)\n",
    "\n",
    "    p0 = [1.0, 0.3, np.median(t)]\n",
    "\n",
    "    try:\n",
    "        params, _ = curve_fit(\n",
    "            _logistic_fn,\n",
    "            t,\n",
    "            y_norm,\n",
    "            p0=p0,\n",
    "            maxfev=10000\n",
    "        )\n",
    "        K, r, t0 = params\n",
    "\n",
    "        last_t = t[-1]\n",
    "        future_t = np.arange(last_t + 1, last_t + 1 + horizon)\n",
    "\n",
    "        t_all = np.concatenate([t, future_t])\n",
    "        y_pred_norm_all = _logistic_fn(t_all, K, r, t0)\n",
    "        y_pred_norm_all = np.clip(y_pred_norm_all, 0.0, 1.0)\n",
    "\n",
    "        y_pred_all = y_min + y_pred_norm_all * (y_max - y_min)\n",
    "        y_future = y_pred_all[len(t):]\n",
    "\n",
    "        last_date = g[\"date\"].max()\n",
    "        future_dates = pd.date_range(\n",
    "            start=last_date + pd.offsets.MonthBegin(1),\n",
    "            periods=horizon,\n",
    "            freq=\"MS\"\n",
    "        )\n",
    "\n",
    "        forecast_df = pd.DataFrame({\n",
    "            \"date\": future_dates,\n",
    "            f\"logistic_{value_col}\": y_future\n",
    "        })\n",
    "\n",
    "        return g, forecast_df\n",
    "\n",
    "    except Exception:\n",
    "        # fallback: linear\n",
    "        return linear_forecast(g, value_col, horizon=horizon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46994c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: örnek bir area+tech için 4 eğri (raw, EWMA, linear, logistic) ===\n",
    "\n",
    "sample = df_ts.iloc[0]\n",
    "tmp = df_ts[\n",
    "    (df_ts[\"auto_focus_area\"] == sample[\"auto_focus_area\"]) &\n",
    "    (df_ts[\"auto_tech_cluster\"] == sample[\"auto_tech_cluster\"])\n",
    "].copy()\n",
    "\n",
    "actual_lin, forecast_lin = linear_forecast(tmp, \"n_total\", horizon=12)\n",
    "actual_log, forecast_log = logistic_forecast(tmp, \"n_total\", horizon=12)\n",
    "\n",
    "span = 6  # 6 aylık EWMA\n",
    "actual_lin = actual_lin.sort_values(\"date\")\n",
    "actual_lin[\"n_total_ewma\"] = actual_lin[\"n_total\"].ewm(span=span, adjust=False).mean()\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "plt.plot(actual_lin[\"date\"], actual_lin[\"n_total\"],\n",
    "         alpha=0.3, label=\"actual volume (raw)\")\n",
    "\n",
    "plt.plot(actual_lin[\"date\"], actual_lin[\"n_total_ewma\"],\n",
    "         linewidth=2, label=\"actual volume (EWMA)\")\n",
    "\n",
    "if forecast_lin is not None:\n",
    "    plt.plot(forecast_lin[\"date\"], forecast_lin[\"forecast_n_total\"],\n",
    "             linestyle=\"--\", label=\"linear forecast\")\n",
    "\n",
    "if forecast_log is not None and \"logistic_n_total\" in forecast_log.columns:\n",
    "    plt.plot(forecast_log[\"date\"], forecast_log[\"logistic_n_total\"],\n",
    "             linestyle=\":\", label=\"logistic (S-curve) forecast\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: global volume + EWMA + quarter işaretleri ===\n",
    "\n",
    "df_global = (\n",
    "    df.groupby(\"date\")\n",
    "      .size()\n",
    "      .reset_index(name=\"n_total\")\n",
    "      .sort_values(\"date\")\n",
    ")\n",
    "\n",
    "df_global[\"n_total_ewma\"] = df_global[\"n_total\"].ewm(span=6, adjust=False).mean()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df_global[\"date\"], df_global[\"n_total\"], alpha=0.3, label=\"global raw\")\n",
    "plt.plot(df_global[\"date\"], df_global[\"n_total_ewma\"], linewidth=2, label=\"global EWMA\")\n",
    "\n",
    "quarters = df_global[df_global[\"date\"].dt.month.isin([1, 4, 7, 10])]\n",
    "plt.scatter(\n",
    "    quarters[\"date\"],\n",
    "    [df_global[\"n_total_ewma\"].min() * 0.95] * len(quarters),\n",
    "    color=\"red\",\n",
    "    s=30,\n",
    "    marker=\"|\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: growth (hacim slope) hesapla ===\n",
    "\n",
    "def estimate_growth(df_ts: pd.DataFrame):\n",
    "    rows = []\n",
    "\n",
    "    for (area, tech), g in df_ts.groupby([\"auto_focus_area\", \"auto_tech_cluster\"]):\n",
    "        t, y = prepare_time_series(g, \"n_total\")\n",
    "        if t is None:\n",
    "            continue\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(t, y)\n",
    "        slope = float(model.coef_[0])\n",
    "\n",
    "        rows.append({\n",
    "            \"auto_focus_area\": area,\n",
    "            \"auto_tech_cluster\": tech,\n",
    "            \"growth_slope_n_docs\": slope,\n",
    "            \"n_docs_last\": y[-1]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_growth = estimate_growth(df_ts)\n",
    "df_growth.sort_values(\"growth_slope_n_docs\", ascending=False).head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Yeni: 1. ve 2. türev temelli stage sınıflandırma ===\n",
    "\n",
    "def _compute_trend_features(g: pd.DataFrame,\n",
    "                            window: int = 6):\n",
    "    \"\"\"\n",
    "    g: tek bir (area, tech) için zaman serisi\n",
    "       kolonlar: [\"date\", \"share_patent\"]\n",
    "    window: son kaç noktadan ortalama türev alınsın (ay)\n",
    "    \"\"\"\n",
    "    g = g.sort_values(\"date\")\n",
    "    y = g[\"share_patent\"].astype(float).values\n",
    "\n",
    "    if len(y) < window + 3:\n",
    "        # çok kısa seri → trend güvenilmez\n",
    "        return None\n",
    "\n",
    "    s = pd.Series(y)\n",
    "\n",
    "    # 1. türev ~ ardışık fark\n",
    "    d1 = s.diff()\n",
    "\n",
    "    # son window içindeki ortalama eğim\n",
    "    d1_recent = d1.iloc[-window:].mean()\n",
    "\n",
    "    # bir önceki window içindeki ortalama eğim\n",
    "    if len(d1) >= 2 * window:\n",
    "        d1_prev = d1.iloc[-2*window:-window].mean()\n",
    "    else:\n",
    "        d1_prev = d1.iloc[:-window].mean()\n",
    "\n",
    "    # 2. türev ~ eğimdeki değişim\n",
    "    d2_recent = d1_recent - d1_prev\n",
    "\n",
    "    last_share = s.iloc[-1]\n",
    "\n",
    "    return last_share, d1_recent, d2_recent\n",
    "\n",
    "\n",
    "def _classify_stage_d1d2(last_share: float,\n",
    "                         d1_recent: float,\n",
    "                         d2_recent: float,\n",
    "                         min_app: float = 0.7,\n",
    "                         max_research: float = 0.3,\n",
    "                         d1_small: float = 0.01):\n",
    "    \"\"\"\n",
    "    last_share  : son patent payı\n",
    "    d1_recent   : son window ortalama 1. türev\n",
    "    d2_recent   : 1. türevdeki değişim (2. türev)\n",
    "    d1_small    : 'yaklaşık sıfır' için eşik\n",
    "    \"\"\"\n",
    "\n",
    "    # sert düşüş: yüksek patent payı + negatif eğim + ivme de negatif\n",
    "    if last_share >= min_app and d1_recent < -d1_small and d2_recent <= 0:\n",
    "        return \"Over-Mature\"\n",
    "\n",
    "    # güçlü uygulama fazı: yüksek pay + pozitif ya da düz eğim\n",
    "    if last_share >= min_app and d1_recent >= -d1_small:\n",
    "        return \"Application Now\"\n",
    "\n",
    "    # hala araştırma: düşük pay + eğim zayıf ya da negatif\n",
    "    if last_share <= max_research and d1_recent <= d1_small:\n",
    "        return \"Still Research\"\n",
    "\n",
    "    # geçiş / hızlanma: pay orta + eğim pozitif, ivme de genelde pozitif\n",
    "    if d1_recent > d1_small:\n",
    "        return \"Transitioning\"\n",
    "\n",
    "    # fallback\n",
    "    return \"Transitioning\"\n",
    "\n",
    "\n",
    "def forecast_paper_to_patent_shift_d1d2(df_ts: pd.DataFrame,\n",
    "                                        window: int = 6,\n",
    "                                        min_total_docs: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    df_ts en az şu kolonlara sahip:\n",
    "      - auto_focus_area\n",
    "      - auto_tech_cluster\n",
    "      - date\n",
    "      - paper\n",
    "      - patent\n",
    "      - n_total\n",
    "      - share_patent\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for (area, tech), g in df_ts.groupby([\"auto_focus_area\", \"auto_tech_cluster\"]):\n",
    "\n",
    "        # toplam doküman sayısı (paper+patent)\n",
    "        if \"n_total\" in g.columns:\n",
    "            total_docs = g[\"n_total\"].sum()\n",
    "        else:\n",
    "            total_docs = (g[\"paper\"] + g[\"patent\"]).sum()\n",
    "\n",
    "        if total_docs < min_total_docs:\n",
    "            continue\n",
    "\n",
    "        feats = _compute_trend_features(g[[\"date\", \"share_patent\"]], window=window)\n",
    "        if feats is None:\n",
    "            continue\n",
    "\n",
    "        last_share, d1_recent, d2_recent = feats\n",
    "        stage = _classify_stage_d1d2(last_share, d1_recent, d2_recent)\n",
    "\n",
    "        rows.append({\n",
    "            \"auto_focus_area\": area,\n",
    "            \"auto_tech_cluster\": tech,\n",
    "            \"last_share_patent\": last_share,\n",
    "            \"d1_recent\": d1_recent,\n",
    "            \"d2_recent\": d2_recent,\n",
    "            \"tech_stage\": stage\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "# kullanım:\n",
    "df_transition = forecast_paper_to_patent_shift_d1d2(df_ts, window=6, min_total_docs=10)\n",
    "df_transition.sort_values(\"tech_stage\").head(40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac802c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "# === 0) DATA LOAD & df_ts hazırlığı (gerekirse) ===\n",
    "DATA_DIR = Path(\"../../01_data\") / \"predictive_model\"\n",
    "df = pd.read_parquet(DATA_DIR / \"df_auto_corpus_area_tech.parquet\")\n",
    "\n",
    "# sadece paper + patent\n",
    "df = df[df[\"source_type\"].isin([\"paper\", \"patent\"])].copy()\n",
    "df = df.dropna(subset=[\"year\", \"month\"])\n",
    "\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "df[\"month\"] = df[\"month\"].astype(int)\n",
    "df[\"date\"] = pd.to_datetime(dict(year=df[\"year\"], month=df[\"month\"], day=1))\n",
    "\n",
    "# aylık toplam doküman\n",
    "g = df.groupby(\n",
    "    [\"auto_focus_area\", \"auto_tech_cluster\", \"date\", \"source_type\"]\n",
    ").size().reset_index(name=\"n\")\n",
    "\n",
    "pivot = g.pivot_table(\n",
    "    index=[\"auto_focus_area\", \"auto_tech_cluster\", \"date\"],\n",
    "    columns=\"source_type\",\n",
    "    values=\"n\",\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "pivot[\"n_total\"] = pivot.get(\"paper\", 0) + pivot.get(\"patent\", 0)\n",
    "\n",
    "df_ts = pivot[[\"auto_focus_area\", \"auto_tech_cluster\", \"date\", \"n_total\"]].copy()\n",
    "\n",
    "# === 1) LOWESS + türev grafikleri ===\n",
    "OUT_DIR = Path(\"tech_lowess_hype\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "FRAC = 0.3          # LOWESS bant genişliği (0.2–0.4 arası oynatabilirsin)\n",
    "MIN_POINTS = 10     # minimum ay sayısı\n",
    "\n",
    "for (area, tech), g in df_ts.groupby([\"auto_focus_area\", \"auto_tech_cluster\"]):\n",
    "    g = g.sort_values(\"date\")\n",
    "\n",
    "    if len(g) < MIN_POINTS:\n",
    "        continue\n",
    "\n",
    "    # zaman ekseni (sadece index)\n",
    "    t = np.arange(len(g), dtype=float)\n",
    "\n",
    "    # log-kümülatif doküman\n",
    "    cum_docs = g[\"n_total\"].cumsum().values.astype(float)\n",
    "    y = np.log1p(cum_docs)  # log(1 + cum)\n",
    "\n",
    "    # LOWESS smoothing\n",
    "    y_smooth = lowess(y, t, frac=FRAC, return_sorted=False)\n",
    "\n",
    "    # türevler\n",
    "    d1 = np.diff(y_smooth)\n",
    "    d2 = np.diff(d1)\n",
    "\n",
    "    t0 = g[\"date\"].values\n",
    "    t1 = g[\"date\"].iloc[1:].values\n",
    "    t2 = g[\"date\"].iloc[2:].values\n",
    "\n",
    "    # === cumulative (S-curve) ===\n",
    "    plt.figure()\n",
    "    plt.plot(t0, np.expm1(y_smooth))  # log'tan geri çevir\n",
    "    plt.title(f\"{tech} – Cumulative docs (LOWESS)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative docs (smoothed)\")\n",
    "    f0 = OUT_DIR / f\"{area}_{tech}_cum_lowess.png\"\n",
    "    plt.savefig(f0)\n",
    "    plt.close()\n",
    "\n",
    "    # === 1. türev ===\n",
    "    plt.figure()\n",
    "    plt.plot(t1, d1)\n",
    "    plt.title(f\"{tech} – 1st Derivative (LOWESS)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Δ log-cum docs\")\n",
    "    f1 = OUT_DIR / f\"{area}_{tech}_d1_lowess.png\"\n",
    "    plt.savefig(f1)\n",
    "    plt.close()\n",
    "\n",
    "    # === 2. türev ===\n",
    "    plt.figure()\n",
    "    plt.plot(t2, d2)\n",
    "    plt.title(f\"{tech} – 2nd Derivative (LOWESS)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Δ² log-cum docs\")\n",
    "    f2 = OUT_DIR / f\"{area}_{tech}_d2_lowess.png\"\n",
    "    plt.savefig(f2)\n",
    "    plt.close()\n",
    "\n",
    "print(\"✅ LOWESS bazlı cumulative + 1. / 2. türev hype grafikleri:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34415b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 10: feature table (df_feat) – time series özetleri + growth + stage ===\n",
    "\n",
    "rows = []\n",
    "for (area, tech), g in df_ts.groupby([\"auto_focus_area\", \"auto_tech_cluster\"]):\n",
    "    g = g.sort_values(\"date\")\n",
    "    n_months = len(g)\n",
    "    if n_months == 0:\n",
    "        continue\n",
    "\n",
    "    n_years = n_months / 12.0\n",
    "    total_docs = g[\"n_total\"].sum()\n",
    "    mean_docs = g[\"n_total\"].mean()\n",
    "    max_docs = g[\"n_total\"].max()\n",
    "    last_docs = g[\"n_total\"].iloc[-1]\n",
    "\n",
    "    mean_share_pat = g[\"share_patent\"].mean()\n",
    "    std_share_pat  = g[\"share_patent\"].std(ddof=0)\n",
    "\n",
    "    rows.append({\n",
    "        \"auto_focus_area\": area,\n",
    "        \"auto_tech_cluster\": tech,\n",
    "        \"n_months\": n_months,\n",
    "        \"n_years\": n_years,\n",
    "        \"total_docs\": total_docs,\n",
    "        \"mean_docs\": mean_docs,\n",
    "        \"max_docs\": max_docs,\n",
    "        \"last_docs\": last_docs,\n",
    "        \"mean_share_patent_ts\": mean_share_pat,\n",
    "        \"std_share_patent_ts\": std_share_pat if pd.notna(std_share_pat) else 0.0,\n",
    "    })\n",
    "\n",
    "df_feat = pd.DataFrame(rows)\n",
    "\n",
    "df_feat = df_feat.merge(\n",
    "    df_growth[\n",
    "        [\"auto_focus_area\", \"auto_tech_cluster\",\n",
    "         \"growth_slope_n_docs\", \"n_docs_last\"]\n",
    "    ],\n",
    "    on=[\"auto_focus_area\", \"auto_tech_cluster\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_feat = df_feat.merge(\n",
    "    df_transition[\n",
    "        [\"auto_focus_area\",\n",
    "         \"auto_tech_cluster\",\n",
    "         \"last_share_patent\",\n",
    "         \"d1_recent\",\n",
    "         \"d2_recent\",\n",
    "         \"tech_stage\",\n",
    "        ]\n",
    "    ],\n",
    "    on=[\"auto_focus_area\", \"auto_tech_cluster\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_feat.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc551a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 11: \"Application pattern\" centroid + distance ===\n",
    "\n",
    "num_cols = [\n",
    "    \"n_months\",\n",
    "    \"n_years\",\n",
    "    \"total_docs\",\n",
    "    \"mean_docs\",\n",
    "    \"max_docs\",\n",
    "    \"last_docs\",\n",
    "    \"mean_share_patent_ts\",\n",
    "    \"std_share_patent_ts\",\n",
    "    \"growth_slope_n_docs\",\n",
    "    \"n_docs_last\",\n",
    "    \"last_share_patent\",\n",
    "    \"forecast_share_patent_mean\",\n",
    "    \"delta_share_patent\",\n",
    "]\n",
    "\n",
    "df_num = df_feat[num_cols].fillna(0.0)\n",
    "\n",
    "mu = df_num.mean()\n",
    "sigma = df_num.std(ddof=0).replace(0, 1.0)\n",
    "df_z = (df_num - mu) / sigma\n",
    "\n",
    "mask_app_rule = df_feat[\"tech_stage\"] == \"Application Now\"\n",
    "df_app_z = df_z[mask_app_rule]\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "centroid_app = df_app_z.mean()\n",
    "distances = norm(df_z.values - centroid_app.values, axis=1)\n",
    "df_feat[\"dist_to_app_pattern\"] = distances\n",
    "\n",
    "d_app = distances[mask_app_rule]\n",
    "q75 = np.quantile(d_app, 0.75)\n",
    "\n",
    "df_feat[\"application_like_by_pattern\"] = df_feat[\"dist_to_app_pattern\"] <= q75\n",
    "\n",
    "df_feat.sort_values(\"dist_to_app_pattern\").head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 12: adjusted tech_stage (pattern tabakası) ===\n",
    "\n",
    "df_feat[\"tech_stage_adjusted\"] = df_feat[\"tech_stage\"]\n",
    "\n",
    "mask_candidate = (\n",
    "    df_feat[\"application_like_by_pattern\"]\n",
    "    & (df_feat[\"last_share_patent\"] > 0.4)\n",
    "    & (df_feat[\"n_years\"] >= 3)\n",
    ")\n",
    "\n",
    "df_feat.loc[mask_candidate, \"tech_stage_adjusted\"] = \"Application Now\"\n",
    "\n",
    "df_feat[\n",
    "    [\n",
    "        \"auto_focus_area\",\n",
    "        \"auto_tech_cluster\",\n",
    "        \"tech_stage\",\n",
    "        \"tech_stage_adjusted\",\n",
    "        \"last_share_patent\",\n",
    "        \"delta_share_patent\",\n",
    "        \"n_years\",\n",
    "        \"dist_to_app_pattern\",\n",
    "    ]\n",
    "].sort_values(\"dist_to_app_pattern\").head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09018bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 13: save outputs ===\n",
    "\n",
    "df_ts.to_parquet(DATA_DIR / \"area_tech_timeseries.parquet\", index=False)\n",
    "df_growth.to_parquet(DATA_DIR / \"forecast_area_tech_growth.parquet\", index=False)\n",
    "df_transition.to_parquet(DATA_DIR / \"forecast_area_tech_transition.parquet\", index=False)\n",
    "df_feat.to_parquet(DATA_DIR / \"area_tech_features_with_stage.parquet\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(DATA_DIR / \"area_tech_timeseries.parquet\")\n",
    "print(DATA_DIR / \"forecast_area_tech_growth.parquet\")\n",
    "print(DATA_DIR / \"forecast_area_tech_transition.parquet\")\n",
    "print(DATA_DIR / \"area_tech_features_with_stage.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20260288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictive_components.analytics import (\n",
    "    load_area_tech_ts,\n",
    "    get_fastest_growing_topics,\n",
    "    get_transitioning_technologies,\n",
    "    get_likely_to_mature_next_year,\n",
    "    plot_simple_timeseries,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e2d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = load_area_tech_ts()\n",
    "df_ts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fast = get_fastest_growing_topics(df_ts, top_n=20)\n",
    "df_fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6391e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transition = get_transitioning_technologies(df_ts, horizon=12)\n",
    "df_transition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffc1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictive_components.analytics import plot_simple_timeseries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plot_simple_timeseries(\n",
    "    df_ts=df_ts,\n",
    "    area=\"Communication_Technologies\",\n",
    "    tech=\"5G\",\n",
    "    value_col=\"n_total\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aef5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mature_next = get_likely_to_mature_next_year(df_ts, horizon=12)\n",
    "df_mature_next\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
