{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c8c2f6",
   "metadata": {},
   "source": [
    "**Notebook 03 is a \"run-once\" setup**\n",
    "\n",
    "- üìù NOTEBOOK 3 - SETUP ONLY\n",
    "- ‚úÖ LLM client configured\n",
    "- ‚úÖ Prompt templates defined  \n",
    "- ‚úÖ Answer generator ready\n",
    "\n",
    "No files saved - this notebook only needs to run once per session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93446b4",
   "metadata": {},
   "source": [
    "# LLM Response Generation\n",
    "\n",
    "**Why we're doing this:**\n",
    " Take retrieved document chunks and generate coherent answers using a language model.\n",
    "\n",
    "**What we're doing:**\n",
    "\n",
    "- Setting up first prototype - done\n",
    "- Setting up the LLM client (Groq/Llama) - done\n",
    "- Creating prompt templates for TRL questions - done\n",
    "- Generating answers from retrieved context - done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7a9148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ COMPONENTS IMPORTED SUCCESSFULLY!\n",
      "‚úì TF-IDF retriever loaded successfully\n",
      "‚úì Template-based RAG answer generator initialized\n",
      "‚úÖ Generation pipeline ready!\n"
     ]
    }
   ],
   "source": [
    "# PERMANENT WORKING IMPORT - USE THIS EVERYWHERE\n",
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "\n",
    "def import_rag_components():\n",
    "    \"\"\"Import RAG components\"\"\"\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # Import retriever\n",
    "    retriever_path = os.path.join(current_dir, 'rag_components', 'retriever.py')\n",
    "    spec = importlib.util.spec_from_file_location(\"retriever\", retriever_path)\n",
    "    retriever_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(retriever_module)\n",
    "    \n",
    "    # Import query_interface  \n",
    "    query_interface_path = os.path.join(current_dir, 'rag_components', 'query_interface.py')\n",
    "    spec = importlib.util.spec_from_file_location(\"query_interface\", query_interface_path)\n",
    "    query_interface_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(query_interface_module)\n",
    "    \n",
    "    # Import answer_generator\n",
    "    answer_generator_path = os.path.join(current_dir, 'rag_components', 'answer_generator.py')\n",
    "    spec = importlib.util.spec_from_file_location(\"answer_generator\", answer_generator_path)\n",
    "    answer_generator_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(answer_generator_module)\n",
    "    \n",
    "    return (retriever_module.DocumentAwareRetriever, \n",
    "            query_interface_module.SimpleQueryInterface,\n",
    "            answer_generator_module.RAGAnswerGenerator)\n",
    "\n",
    "# Import the components\n",
    "DocumentAwareRetriever, SimpleQueryInterface, RAGAnswerGenerator = import_rag_components()\n",
    "print(\"üéâ COMPONENTS IMPORTED SUCCESSFULLY!\")\n",
    "\n",
    "# Continue with code\n",
    "VECTOR_INDEX_PATH = \"../../04_models/vector_index\"\n",
    "retriever = DocumentAwareRetriever(VECTOR_INDEX_PATH)\n",
    "query_interface = SimpleQueryInterface(retriever)\n",
    "answer_generator = RAGAnswerGenerator(query_interface)\n",
    "print(\"‚úÖ Generation pipeline ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b256e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: groq in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (0.36.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from groq) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from groq) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->groq) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->groq) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/manueltimowolf/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b686a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Groq client initialized successfully\n",
      "üéâ LLM client ready for integration!\n"
     ]
    }
   ],
   "source": [
    "# CELL: LLM Client Setup\n",
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "def setup_groq_client():\n",
    "    \"\"\"Set up and return Groq client with error handling\"\"\"\n",
    "    api_key = os.getenv('GROQ_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        raise ValueError(\"‚ùå GROQ_API_KEY not found in environment variables\")\n",
    "    \n",
    "    client = Groq(api_key=api_key)\n",
    "    print(\"‚úÖ Groq client initialized successfully\")\n",
    "    return client\n",
    "\n",
    "# Test the client\n",
    "try:\n",
    "    groq_client = setup_groq_client()\n",
    "    print(\"üéâ LLM client ready for integration!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize LLM client: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962956a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM Connected: API connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL: Test LLM Connection\n",
    "# Why: Verify Groq API works and model responds correctly\n",
    "# What: Send simple test query to confirm setup is functional\n",
    "def test_llm_connection():\n",
    "    try:\n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",  # Fast, free model for testing\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Reply only with 'API connected'\"}],\n",
    "            max_tokens=10,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        print(f\"‚úÖ LLM Connected: {response.choices[0].message.content}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLM Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_llm_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d06556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ LLM integration code ready!\n"
     ]
    }
   ],
   "source": [
    "# CELL: Integrate with Your Generator\n",
    "def generate_with_llm(query, context):\n",
    "    \"\"\"Generate answer using Groq/Llama\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following context, answer the user's question.\n",
    "    \n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"üöÄ LLM integration code ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85afdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ REGULAR QUESTION PROMPT:\n",
      "Includes TRL section: False\n",
      "---\n",
      "üîπ TRL QUESTION PROMPT:\n",
      "Includes TRL section: True\n",
      "\n",
      "‚úÖ Universal prompt template ready!\n",
      "‚úÖ Automatically includes TRL guidance for maturity questions\n",
      "‚úÖ Single template for all query types\n"
     ]
    }
   ],
   "source": [
    "# CELL: Universal Prompt Template\n",
    "# Why: Single template that adapts to both regular and TRL queries automatically\n",
    "# What: Smart template that detects when to include maturity analysis\n",
    "\n",
    "UNIVERSAL_PROMPT_TEMPLATE = \"\"\"\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "USER QUESTION:\n",
    "{question}\n",
    "\n",
    "ANALYSIS INSTRUCTIONS:\n",
    "1. Provide a comprehensive answer based strictly on the context provided\n",
    "2. Cite specific sources for each key point using [Source: filename]\n",
    "3. If the context is insufficient, acknowledge what cannot be answered\n",
    "\n",
    "{trl_section}\n",
    "\n",
    "ADDITIONAL GUIDELINES:\n",
    "- For technology maturity questions: assess development stage and transition evidence\n",
    "- For trend questions: identify velocity, drivers, and key players  \n",
    "- For forecasting: distinguish near-term vs long-term developments\n",
    "- For descriptive questions: provide specific examples and entities\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "def build_smart_prompt(question, context):\n",
    "    \"\"\"Build adaptive prompt that includes TRL guidance only when needed\"\"\"\n",
    "    \n",
    "    # Detect if this is a technology maturity question\n",
    "    maturity_keywords = ['trl', 'mature', 'transition', 'academy to application', \n",
    "                        'commercial', 'moving from academy', 'readiness', 'development stage']\n",
    "    \n",
    "    question_lower = question.lower()\n",
    "    is_maturity_question = any(keyword in question_lower for keyword in maturity_keywords)\n",
    "    \n",
    "    # Include TRL section only for maturity questions\n",
    "    if is_maturity_question:\n",
    "        trl_section = \"\"\"\n",
    "TECHNOLOGY MATURITY ASSESSMENT:\n",
    "- When discussing technology readiness, reference these stages:\n",
    "  * Research Phase (TRL 1-4): Basic research, lab validation\n",
    "  * Development Phase (TRL 5-6): Prototyping, testing  \n",
    "  * Commercialization Phase (TRL 7-9): Deployment, scaling\n",
    "- Assess current stage based on evidence in context\n",
    "- Identify transition indicators and timelines\n",
    "\"\"\"\n",
    "    else:\n",
    "        trl_section = \"\"\n",
    "    \n",
    "    prompt = UNIVERSAL_PROMPT_TEMPLATE.format(\n",
    "        context=context,\n",
    "        question=question,\n",
    "        trl_section=trl_section\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Test the universal template\n",
    "def test_universal_prompt():\n",
    "    \"\"\"Test that the template adapts to different question types\"\"\"\n",
    "    \n",
    "    test_context = \"Sample context about technology development...\"\n",
    "    \n",
    "    # Test regular question\n",
    "    regular_question = \"Which startups work on AI for automotive?\"\n",
    "    regular_prompt = build_smart_prompt(regular_question, test_context)\n",
    "    print(\"üîπ REGULAR QUESTION PROMPT:\")\n",
    "    print(\"Includes TRL section:\", \"TECHNOLOGY MATURITY ASSESSMENT\" in regular_prompt)\n",
    "    print(\"---\")\n",
    "    \n",
    "    # Test TRL question  \n",
    "    trl_question = \"Which quantum computing research is moving from academy to application?\"\n",
    "    trl_prompt = build_smart_prompt(trl_question, test_context)\n",
    "    print(\"üîπ TRL QUESTION PROMPT:\")\n",
    "    print(\"Includes TRL section:\", \"TECHNOLOGY MATURITY ASSESSMENT\" in trl_prompt)\n",
    "    \n",
    "    return regular_prompt, trl_prompt\n",
    "\n",
    "# Run test\n",
    "regular_prompt, trl_prompt = test_universal_prompt()\n",
    "\n",
    "print(\"\\n‚úÖ Universal prompt template ready!\")\n",
    "print(\"‚úÖ Automatically includes TRL guidance for maturity questions\")\n",
    "print(\"‚úÖ Single template for all query types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de134455",
   "metadata": {},
   "source": [
    "# Response Quality Setup\n",
    "\n",
    "**Why we're doing this:** \n",
    "Ensure answers are relevant and properly cite sources.\n",
    "\n",
    "**What we're doing:**\n",
    "\n",
    "- Checking if the pipeline works and our LLM integration and prompt template can return something nice. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c435c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TESTING ALL USER QUERIES WITH DYNAMIC SOURCE COUNT & STARTUP BOOSTER\n",
      "Note: Predictive section not yet integrated - focusing on RAG performance\n",
      "\n",
      "üß™ QUERY 1: 'Which startups work on AI for automotive?'\n",
      "============================================================\n",
      "1. üîç Retrieving documents (k=4)...\n",
      "   üöÄ Boosting startups file for this query...\n",
      "   ‚úÖ Added 2 startup-specific results\n",
      "   ‚úÖ Found 4 relevant chunks\n",
      "2. üìù Building prompt...\n",
      "3. ü§ñ Generating answer with LLM...\n",
      "4. üìä RESULTS:\n",
      "ANSWER: Based on the provided context, there is no direct information about startups working on AI for automotive applications. However, we can make some inferences and connections.\n",
      "\n",
      "The research paper \"Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience\" [Source: Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience] discusses the impact of generative AI on the automotive industry, focusing on its applications, benefits, and potential challenges. This paper explores the use of generative AI technologies like GANs and VAEs in various aspects of automotive design, manufacturing, and autonomous driving.\n",
      "\n",
      "Although there is no direct mention of startups working on AI for automotive, the paper's focus on generative AI and its applications in the automotive industry suggests that there may be startups working on related projects.\n",
      "\n",
      "However, without explicit information about startups working on AI for automotive, we cannot provide a comprehensive answer to the question.\n",
      "\n",
      "If we look at the startups mentioned in the context, none of them are directly related to AI for automotive applications. Boxure, StartupsFM, Web Espy, Silver Tongue, Bus Rush, and VOLK are mentioned, but their descriptions do not indicate any connection to AI for automotive.\n",
      "\n",
      "Therefore, based on the provided context, we cannot conclusively answer the question about which startups work on AI for automotive.\n",
      "SOURCES: 4 documents (k=4)\n",
      "   üöÄ Startup boost was applied to this query\n",
      "   1. üöÄ Startup Innovation Database (Score: 0.474)\n",
      "   2. üöÄ Startup Innovation Database (Score: 0.466)\n",
      "   3. Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience (Score: 0.477)\n",
      "   4. DRIVE Framework: Synthetic Dialog Data for Intelligent Vehicles (Score: 0.444)\n",
      "‚úÖ Query completed successfully!\n",
      "\n",
      "üß™ QUERY 2: 'Summarize the latest research on AI and autonomous driving.'\n",
      "============================================================\n",
      "1. üîç Retrieving documents (k=5)...\n",
      "   ‚úÖ Found 5 relevant chunks\n",
      "2. üìù Building prompt...\n",
      "3. ü§ñ Generating answer with LLM...\n",
      "4. üìä RESULTS:\n",
      "ANSWER: Based on the provided research papers, here is a summary of the latest research on AI and autonomous driving:\n",
      "\n",
      "**Advancements in Autonomous Driving Systems**\n",
      "\n",
      "Recent research has focused on developing more robust and accurate autonomous driving systems. For instance, Gaia-1 was offered for autonomous driving prediction and simulation of scenarios by Hu et al. (2023) [23] through a generative AI-driven world model [1]. Similarly, Marathe et al. (2023) [35] proposed Wedge, a novel dataset synthesized from artificial intelligence models that focus on multi-weather conditions for autonomous driving [1].\n",
      "\n",
      "**Simulating Difficult Driving Scenarios**\n",
      "\n",
      "Al. (2024) [59] presented the ability to simulate difficult driving scenarios, which could help polish and test autonomous driving systems under varied conditions [1]. This is crucial for ensuring the safety and reliability of autonomous vehicles.\n",
      "\n",
      "**Multimodal World Models**\n",
      "\n",
      "Recent research has also focused on developing multimodal world models for autonomous driving. For example, BEVWorld: A Multimodal World Model for Autonomous Driving via Unified BEV Latent Space was proposed by Y. Zhang et al. (2024) [158]. Another example is MUVO: A Multimodal World Model with Spatial Representations for Autonomous Driving, proposed by D. Bogdoll et al. (2024) [159].\n",
      "\n",
      "**Occupancy Forecasting and Planning**\n",
      "\n",
      "Occupancy forecasting and planning are critical components of autonomous driving systems. Recent research has proposed various approaches to address these challenges. For example, Driving in the Occupancy World: Vision-Centric 4D Occupancy Forecasting and Planning via World Models for Autonomous Driving was proposed by Y. Yang et al. (2025) [160].\n",
      "\n",
      "**Path Planning and Architecture**\n",
      "\n",
      "Path planning and architecture are essential components of autonomous driving systems. Recent research has proposed various approaches to address these challenges. For example, LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning was proposed by N. Nayakanti et al. (2024) [235]. A functional reference architecture for autonomous driving was proposed by S. Behere and M. T√∂rngren (2016) [236].\n",
      "\n",
      "**End-to-End Autonomous Driving**\n",
      "\n",
      "End-to-end autonomous driving is a rapidly evolving field, with recent research focusing on developing more accurate and robust systems. For example, Senna: Bridging Large Vision-Language Models and End-to-End Autonomous Driving was proposed by B. Jiang\n",
      "SOURCES: 5 documents (k=5)\n",
      "   1. Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience (Score: 0.527)\n",
      "   2. Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience (Score: 0.447)\n",
      "   3. Generative Ai For Autonomous Driving A Review (Score: 0.419)\n",
      "   4. Generative Ai For Autonomous Driving A Review (Score: 0.391)\n",
      "   5. Generative Ai For Autonomous Driving A Review (Score: 0.389)\n",
      "‚úÖ Query completed successfully!\n",
      "\n",
      "üß™ QUERY 3: 'Summarize latest tech trends in development of AI agents'\n",
      "============================================================\n",
      "1. üîç Retrieving documents (k=5)...\n",
      "   ‚úÖ Found 5 relevant chunks\n",
      "2. üìù Building prompt...\n",
      "3. ü§ñ Generating answer with LLM...\n",
      "4. üìä RESULTS:\n",
      "ANSWER: Based on the provided context from McKinsey Technology Trends Outlook 2025 and BCG AI Value 2025, here's a summary of the latest tech trends in the development of AI agents:\n",
      "\n",
      "**Key Developments:**\n",
      "\n",
      "1. **Agentic AI Platforms:** Developers are building AI-powered, general-purpose agent platforms, enabling autonomous decision-making and interagent communication [Source: McKinsey Technology Trends Outlook 2025].\n",
      "2. **Specialized Agents:** Companies are adding agentic capabilities to their existing platforms, and specialized agents are being designed for deep research [Source: McKinsey Technology Trends Outlook 2025].\n",
      "3. **AI-to-AI Communication:** Advances in AI-to-AI communication have implications for robotics, complex problem-solving, and other fields, but also raise concerns about transparency and control [Source: McKinsey Technology Trends Outlook 2025].\n",
      "4. **General Agent Platforms:** Companies like Google and OpenAI are developing general agent platforms, such as Gemini 2.0 and Operator, respectively [Source: McKinsey Technology Trends Outlook 2025].\n",
      "\n",
      "**Trend Drivers:**\n",
      "\n",
      "1. **Industry Adoption:** Many industries are exploring the use of agentic virtual coworkers for various functions and roles, driven by the potential of agentic AI [Source: McKinsey Technology Trends Outlook 2025].\n",
      "2. **Investment and Job Postings:** The trend has attracted significant investment, with $1.1 billion in equity investment in 2023-24, and a 985% increase in job postings [Source: McKinsey Technology Trends Outlook 2025].\n",
      "3. **Responsible AI:** Efforts are underway to establish guardrails for AI, reflecting a movement within the tech industry known as \"responsible AI\" [Source: McKinsey Technology Trends Outlook 2025].\n",
      "\n",
      "**Key Players:**\n",
      "\n",
      "1. **Google:** Developing general agent platforms, such as Gemini 2.0 [Source: McKinsey Technology Trends Outlook 2025].\n",
      "2. **OpenAI:** Developing general agent platforms, such as Operator [Source: McKinsey Technology Trends Outlook 2025].\n",
      "3. **BCG:** Researching the value of AI and its impact on the workforce [Source: BCG AI Value 2025].\n",
      "\n",
      "**Challenges and Concerns:**\n",
      "\n",
      "1. **Trust, Governance, and Liability:** Rising concerns about trust, governance, and liability are influencing the development and deployment of agentic AI [Source: McKinsey Technology Trends Outlook 2025].\n",
      "2\n",
      "SOURCES: 5 documents (k=5)\n",
      "   1. McKinsey Technology Trends Outlook 2025 (Score: 0.502)\n",
      "   2. Bcg Ai Value 2025 (Score: 0.467)\n",
      "   3. McKinsey Technology Trends Outlook 2025 (Score: 0.440)\n",
      "   4. McKinsey Technology Trends Outlook 2025 (Score: 0.410)\n",
      "   5. McKinsey Technology Trends Outlook 2025 (Score: 0.398)\n",
      "‚úÖ Query completed successfully!\n",
      "\n",
      "üß™ QUERY 4: 'Summarize the key pain points/use cases mentioned in these sources about automotive AI.'\n",
      "============================================================\n",
      "1. üîç Retrieving documents (k=5)...\n",
      "   ‚úÖ Found 5 relevant chunks\n",
      "2. üìù Building prompt...\n",
      "3. ü§ñ Generating answer with LLM...\n",
      "4. üìä RESULTS:\n",
      "ANSWER: Based on the provided sources, the key pain points and use cases mentioned in the context of automotive AI are:\n",
      "\n",
      "1. **Lack of access to AI tools**: In relatively immature sectors, less than 50% of employees have access to AI tools, hindering the adoption of AI in core functions. [Source: Bcg AI Value 2025]\n",
      "\n",
      "2. **High workflow complexity**: AI agents incorporate predictive as well as GenAI, and vary enormously in terms of workflow complexity, making it challenging to implement AI in various workflows. [Source: Bcg AI Value 2025]\n",
      "\n",
      "3. **Limited use of AI in core functions**: In sectors such as airlines and telecommunications, AI's contribution to value in core functions pushes 80%, but in other sectors like chemicals, oil and gas, and machinery and automation, the shift toward AI use in core functions is still in its early stages. [Source: Bcg AI Value 2025]\n",
      "\n",
      "4. **Challenges in implementing generative AI**: The paper on \"Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience\" highlights the challenges in implementing generative AI in the automotive industry, including the need for innovative applications and the potential risks associated with its adoption. [Source: Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience]\n",
      "\n",
      "5. **Need for AI ecosystems and partnerships**: Strategic users of ecosystems are significantly more likely to adopt GenAI and agentic AI, reuse models and prompts across workflows, and generate greater value. [Source: Bcg AI Value 2025]\n",
      "\n",
      "6. **Limited use of machine learning**: Machine learning (ML) is a branch of AI that uses algorithms and statistical models to identify patterns in data and automatically improve performance, but its use is still limited in the automotive industry. [Source: Bcg AI Value 2025]\n",
      "\n",
      "7. **Innovative applications in automotive design, manufacturing, and autonomous driving**: The paper on \"Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience\" highlights the potential applications of generative AI in automotive design, manufacturing, and autonomous driving, including the use of GANs and V AEs. [Source: Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience]\n",
      "\n",
      "8. **Use cases in voice assistant, infotainment, and other areas**: The paper on \"Gen Ai In Automotive Applications Challenges And Opportunities\n",
      "SOURCES: 5 documents (k=5)\n",
      "   1. Bcg Ai Value 2025 (Score: 0.435)\n",
      "   2. Gen Ai In Automotive Applications Challenges And Opportunities With A Case Study On In-Vehicle Experience (Score: 0.432)\n",
      "   3. Automotive Software and Electronics 2030 Report (Score: 0.419)\n",
      "   4. Bcg Ai Value 2025 (Score: 0.369)\n",
      "   5. Startup Innovation Database (Score: 0.366)\n",
      "‚úÖ Query completed successfully!\n",
      "\n",
      "üß™ QUERY 5: 'Show me recent reports on technology trends.'\n",
      "============================================================\n",
      "1. üîç Retrieving documents (k=5)...\n",
      "   ‚úÖ Found 5 relevant chunks\n",
      "2. üìù Building prompt...\n",
      "3. ü§ñ Generating answer with LLM...\n",
      "4. üìä RESULTS:\n",
      "ANSWER: Based on the provided context, here are recent reports on technology trends:\n",
      "\n",
      "**Artificial Intelligence (AI)**\n",
      "\n",
      "* AI is a powerful technology wave that is driving innovation and addressing critical challenges across sectors. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "* AI is increasingly combining with other trends to accelerate progress within individual domains and unlock new possibilities at the intersections. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "* AI is being used to accelerate the training of robots, advance scientific discoveries in bioengineering, optimize energy systems, and more. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "**5G Networks**\n",
      "\n",
      "* 5G networks are transforming space communication by integrating with satellite systems to extend high-speed, low-latency internet coverage to remote areas and improve global telecommunications. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "**Future of Energy and Sustainability Technologies**\n",
      "\n",
      "* The trend of electrification and renewables and climate technologies beyond electrification have been combined into a single trend: future of energy and sustainability technologies. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "* This trend is expected to drive innovation and address critical challenges across sectors. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "**Cloud and Edge Computing**\n",
      "\n",
      "* Levels of equity investment in cloud and edge computing increased despite the broader market dip in 2023. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "* Investments in cloud and edge computing rebounded in 2024 to higher levels than they achieved two years prior. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "**Bioengineering**\n",
      "\n",
      "* Levels of equity investment in bioengineering increased despite the broader market dip in 2023. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "* Investments in bioengineering rebounded in 2024 to higher levels than they achieved two years prior. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "**Space Technologies**\n",
      "\n",
      "* Levels of equity investment in space technologies increased despite the broader market dip in 2023. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "* Investments in space technologies rebounded in 2024 to higher levels than they achieved two years prior. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "**Immersive Reality**\n",
      "\n",
      "* Technicians use augmented reality goggles that provide visual guidance to help them maintain and repair complex turbine systems safely. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "**\n",
      "SOURCES: 5 documents (k=5)\n",
      "   1. Startup Innovation Database (Score: 0.465)\n",
      "   2. McKinsey Technology Trends Outlook 2025 (Score: 0.459)\n",
      "   3. McKinsey Technology Trends Outlook 2025 (Score: 0.403)\n",
      "   4. McKinsey Technology Trends Outlook 2025 (Score: 0.391)\n",
      "   5. McKinsey Technology Trends Outlook 2025 (Score: 0.384)\n",
      "‚úÖ Query completed successfully!\n",
      "\n",
      "üß™ QUERY 6: 'Which technologies are likely to mature next year?'\n",
      "============================================================\n",
      "1. üîç Retrieving documents (k=4)...\n",
      "   ‚úÖ Found 4 relevant chunks\n",
      "2. üìù Building prompt...\n",
      "3. ü§ñ Generating answer with LLM...\n",
      "4. üìä RESULTS:\n",
      "ANSWER: Based on the provided context, it is challenging to determine which technologies are likely to mature next year with high accuracy. However, we can assess the current development stage and transition indicators of the mentioned technologies.\n",
      "\n",
      "**Artificial Intelligence (AI)**\n",
      "\n",
      "According to the McKinsey Technology Trends Outlook 2025, AI is an overarching category that has replaced four previous trends. This suggests that AI is a mature technology with a significant presence in the market. However, the report also mentions that the selection and definition of trends have been updated to reflect the evolution of technology trends, indicating that AI is still evolving.\n",
      "\n",
      "Source: McKinsey Technology Trends Outlook 2025\n",
      "\n",
      "**Future of Energy and Sustainability Technologies**\n",
      "\n",
      "This trend combines electrification and renewables and climate technologies beyond electrification. The report mentions that the data sources and keywords have been updated, suggesting that this trend is still in the development phase.\n",
      "\n",
      "Source: McKinsey Technology Trends Outlook 2025\n",
      "\n",
      "**Emerging Technologies of 2025**\n",
      "\n",
      "The World Economic Forum's Emerging Technologies 2025 report highlights 10 emerging technologies, including:\n",
      "\n",
      "1. **Extended Reality**: This technology is already being used in various industries, such as gaming and education. It is likely to mature in the near term.\n",
      "2. **Quantum Computing**: This technology is still in the research phase, with significant breakthroughs expected in the next few years.\n",
      "3. **Synthetic Biology**: This technology is still in the development phase, with significant investments being made in the field.\n",
      "4. **Autonomous Systems**: This technology is already being used in various industries, such as transportation and logistics. It is likely to mature in the near term.\n",
      "5. **Internet of Bodies (IoB)**: This technology is still in the research phase, with significant breakthroughs expected in the next few years.\n",
      "6. **Digital Identity**: This technology is already being used in various industries, such as finance and healthcare. It is likely to mature in the near term.\n",
      "7. **Climate Engineering**: This technology is still in the development phase, with significant investments being made in the field.\n",
      "8. **Advanced Nuclear Power**: This technology is still in the development phase, with significant investments being made in the field.\n",
      "9. **Personalized Medicine**: This technology is already being used in various industries, such as healthcare and biotechnology. It is likely to mature in the near term.\n",
      "10. **Space Technologies**: This technology is still in the research phase, with significant breakthroughs expected in the\n",
      "SOURCES: 4 documents (k=4)\n",
      "   1. McKinsey Technology Trends Outlook 2025 (Score: 0.432)\n",
      "   2. World Economic Forum: Emerging Technologies 2025 (Score: 0.407)\n",
      "   3. World Economic Forum: Emerging Technologies 2025 (Score: 0.396)\n",
      "   4. Startup Innovation Database (Score: 0.388)\n",
      "‚úÖ Query completed successfully!\n",
      "\n",
      "üß™ QUERY 7: 'Which AI research topics are growing fastest?'\n",
      "============================================================\n",
      "1. üîç Retrieving documents (k=4)...\n",
      "   ‚úÖ Found 4 relevant chunks\n",
      "2. üìù Building prompt...\n",
      "3. ü§ñ Generating answer with LLM...\n",
      "4. üìä RESULTS:\n",
      "ANSWER: Based on the provided context, it appears that there is limited information on AI research topics. However, we can infer some insights from the reports on future-built companies and technology trends.\n",
      "\n",
      "From the BCG report, \"Build for the Future 2025 Global Study,\" we can see that future-built companies are more likely to have appointed a chief AI officer and have a higher maturity in implementing responsible AI guardrails and governance. This suggests that companies are recognizing the importance of AI and are investing in the necessary infrastructure to support its development and implementation.\n",
      "\n",
      "The McKinsey report, \"Technology Trends Outlook 2025,\" highlights several challenges and concerns related to AI, including cybersecurity and privacy concerns, ethical concerns about data governance, and sustainability issues. However, it does not provide information on specific AI research topics.\n",
      "\n",
      "Given the limited information on AI research topics, it is difficult to determine which topics are growing fastest. However, we can infer that companies are increasingly investing in AI research and development, and that there is a growing need for responsible AI governance and sustainability.\n",
      "\n",
      "Therefore, some potential AI research topics that may be growing in importance include:\n",
      "\n",
      "1. Responsible AI governance: As companies recognize the importance of AI, they are also recognizing the need for responsible AI governance to ensure that AI systems are developed and implemented in a way that is fair, transparent, and accountable. [Source: BCG Build for the Future 2025 Global Study]\n",
      "2. AI sustainability: As AI systems require increasing computational resources, there is a growing need to address the environmental impact of AI development and deployment. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "3. Explainability and transparency: As AI systems become more complex, there is a growing need for explainability and transparency in AI decision-making processes. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "4. AI ethics: As AI systems raise ethical concerns about data governance, justice, and fairness, there is a growing need for research on AI ethics and the development of AI systems that are fair, transparent, and accountable. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "It is worth noting that these topics are not necessarily \"growing fastest\" in terms of research, but rather are becoming increasingly important as companies and leaders recognize the need for responsible AI development and implementation.\n",
      "SOURCES: 4 documents (k=4)\n",
      "   1. Startup Innovation Database (Score: 0.443)\n",
      "   2. Startup Innovation Database (Score: 0.396)\n",
      "   3. Bcg Ai Value 2025 (Score: 0.386)\n",
      "   4. McKinsey Technology Trends Outlook 2025 (Score: 0.385)\n",
      "‚úÖ Query completed successfully!\n",
      "\n",
      "üß™ QUERY 8: 'Which research topics in quantum computing are moving from academy to application?'\n",
      "============================================================\n",
      "1. üîç Retrieving documents (k=4)...\n",
      "   ‚úÖ Found 4 relevant chunks\n",
      "2. üìù Building prompt...\n",
      "3. ü§ñ Generating answer with LLM...\n",
      "4. üìä RESULTS:\n",
      "ANSWER: Based on the provided context, the following research topics in quantum computing are moving from academia to application:\n",
      "\n",
      "1. **Quantum Error Correction**: The first successful demonstration of low-latency quantum error correction was achieved by IBM in their European quantum data center, marking a significant milestone in the transition from research to application. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "2. **Quantum Advantage**: Google's latest quantum chip, Willow, performed a benchmark computation that would take one of today's fastest supercomputers 10 septillion years, demonstrating quantum advantage and paving the way for practical applications. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "3. **Quantum Key Distribution (QKD)**: Quantum key distribution is being explored for secure data transfer, with companies like IBM and Microsoft working on practical implementations. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "4. **Accelerated Quantum Supercomputing**: The integration of leading quantum hardware with AI supercomputers, as proposed by Nvidia's NVAQC, aims to overcome pressing challenges in quantum computing and develop practical devices. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "5. **Quantum Computing for Industrial-Scale Problems**: Microsoft's Majorana 1 chip is expected to enable quantum computers to solve meaningful, industrial-scale problems in years rather than decades, marking a significant shift from research to application. [Source: McKinsey Technology Trends Outlook 2025]\n",
      "\n",
      "Technology Maturity Assessment:\n",
      "\n",
      "* **Quantum Error Correction**: Currently in the **Development Phase (TRL 5-6)**, with IBM's demonstration of low-latency quantum error correction in their European quantum data center. Transition indicators: successful demonstration, practical implementation.\n",
      "* **Quantum Advantage**: Currently in the **Development Phase (TRL 5-6)**, with Google's Willow chip demonstrating quantum advantage. Transition indicators: practical implementation, benchmark computations.\n",
      "* **Quantum Key Distribution (QKD)**: Currently in the **Research Phase (TRL 1-4)**, with companies exploring practical implementations. Transition indicators: research advancements, practical demonstrations.\n",
      "* **Accelerated Quantum Supercomputing**: Currently in the **Research Phase (TRL 1-4)**, with Nvidia's NVAQC proposing a concept for integrating quantum hardware with AI supercomputers. Transition indicators: research advancements, practical demonstrations.\n",
      "* **Quantum Computing for Industrial-Scale Problems**: Currently in the **Development Phase (TRL 5-6)**\n",
      "SOURCES: 4 documents (k=4)\n",
      "   1. McKinsey Technology Trends Outlook 2025 (Score: 0.651)\n",
      "   2. McKinsey Technology Trends Outlook 2025 (Score: 0.649)\n",
      "   3. McKinsey Technology Trends Outlook 2025 (Score: 0.649)\n",
      "   4. McKinsey Technology Trends Outlook 2025 (Score: 0.609)\n",
      "‚úÖ Query completed successfully!\n",
      "\n",
      "üéâ TESTING COMPLETE!\n",
      "‚úÖ Successful queries: 8/8\n",
      "üìÅ Individual results saved to: ../../07_testsdemo/test_outputs/demo_results/\n",
      "üìä Consolidated results: ../../07_testsdemo/test_outputs/demo_results/all_user_queries_with_startup_boost_20251126_1141.json\n",
      "\n",
      "üìà QUERY PERFORMANCE SUMMARY:\n",
      "  Q1: k=4, 4 sources üöÄ, 1487 chars\n",
      "  Q2: k=5, 5 sources, 2461 chars\n",
      "  Q3: k=5, 5 sources, 2328 chars\n",
      "  Q4: k=5, 5 sources, 2485 chars\n",
      "  Q5: k=5, 5 sources, 2585 chars\n",
      "  Q6: k=4, 4 sources, 2665 chars\n",
      "  Q7: k=4, 4 sources, 2546 chars\n",
      "  Q8: k=4, 4 sources, 2619 chars\n",
      "\n",
      "üìù Note: Predictive model integration pending - currently testing RAG pipeline only\n"
     ]
    }
   ],
   "source": [
    "# CELL: Test All User Queries with Dynamic Source Count & Startup Booster\n",
    "# Why: Validate pipeline performance with intelligent source retrieval and startup boosting\n",
    "# What: Run all 8 user queries with dynamic k-value and startup file enhancement\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def determine_source_count(question):\n",
    "    \"\"\"Dynamically determine how many sources to retrieve based on question type\"\"\"\n",
    "    question_lower = question.lower()\n",
    "    \n",
    "    if any(keyword in question_lower for keyword in ['summarize', 'trends', 'overview', 'comprehensive']):\n",
    "        return 5  # More sources for comprehensive questions\n",
    "    elif any(keyword in question_lower for keyword in ['which', 'list', 'show me']):\n",
    "        return 4  # Medium for listing questions\n",
    "    elif any(keyword in question_lower for keyword in ['specific', 'exact', 'precise']):\n",
    "        return 2  # Fewer for very specific questions\n",
    "    else:\n",
    "        return 3  # Default\n",
    "\n",
    "def format_source_name(source_file):\n",
    "    \"\"\"Convert file names to human-readable format for better UX\"\"\"\n",
    "    name_mapping = {\n",
    "        # Automotive Papers\n",
    "        'a_benchmark_framework_for_AL_models_in_automotive_aerodynamics.txt': 'Benchmark Framework for AI Models in Automotive Aerodynamics',\n",
    "        'AL_agents_in_engineering_design_a_multiagent_framework_for_aesthetic_and_aerodynamic_car_design.txt': 'AI Agents in Engineering Design: Multiagent Framework for Car Design',\n",
    "        'automating_automotive_software_development_a_synergy_of_generative_AL_and_formal_methods.txt': 'Automating Automotive Software Development: Generative AI and Formal Methods',\n",
    "        'automotive-software-and-electronics-2030-full-report.txt': 'Automotive Software and Electronics 2030 Report',\n",
    "        'drive_disfluency-rich_synthetic_dialog_data_generation_framework_for_intelligent_vehicle_environments.txt': 'DRIVE Framework: Synthetic Dialog Data for Intelligent Vehicles',\n",
    "        'Embedded_acoustic_intelligence_for_automotive_systems.txt': 'Embedded Acoustic Intelligence for Automotive Systems',\n",
    "        'enhanced_drift_aware_computer_vision_achitecture_for_autonomous_driving.txt': 'Enhanced Drift-Aware Computer Vision for Autonomous Driving',\n",
    "        'Gen_AL_in_automotive_applications_challenges_and_opportunities_with_a_case_study_on_in-vehicle_experience.txt': 'Generative AI in Automotive: Applications and Challenges',\n",
    "        'generative_AL_for_autonomous_driving_a_review.txt': 'Generative AI for Autonomous Driving: A Review',\n",
    "        'leveraging_vision_language_models_for_visual_grounding_and_analysis_of_automative_UI.txt': 'Vision-Language Models for Automotive UI Analysis',\n",
    "        \n",
    "        # Tech Reports\n",
    "        'bog_ai_value_2025.txt': 'Boston Consulting Group: AI Value Creation 2025',\n",
    "        'mckinsey_tech_trends_2025.txt': 'McKinsey Technology Trends Outlook 2025',\n",
    "        'wef_emerging_tech_2025.txt': 'World Economic Forum: Emerging Technologies 2025',\n",
    "        'startups_processed.txt': 'Startup Innovation Database',\n",
    "    }\n",
    "    return name_mapping.get(source_file, source_file.replace('.txt', '').replace('_', ' ').title())\n",
    "\n",
    "# Define user queries\n",
    "USER_QUERIES = {\n",
    "    1: \"Which startups work on AI for automotive?\",\n",
    "    2: \"Summarize the latest research on AI and autonomous driving.\",\n",
    "    3: \"Summarize latest tech trends in development of AI agents\",\n",
    "    4: \"Summarize the key pain points/use cases mentioned in these sources about automotive AI.\",\n",
    "    5: \"Show me recent reports on technology trends.\",\n",
    "    6: \"Which technologies are likely to mature next year?\",\n",
    "    7: \"Which AI research topics are growing fastest?\",\n",
    "    8: \"Which research topics in quantum computing are moving from academy to application?\"\n",
    "}\n",
    "\n",
    "def test_complete_pipeline(question, query_id):\n",
    "    \"\"\"Test the full RAG pipeline with dynamic source count and startup boosting\"\"\"\n",
    "    print(f\"üß™ QUERY {query_id}: '{question}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Determine optimal source count\n",
    "        k = determine_source_count(question)\n",
    "        print(f\"1. üîç Retrieving documents (k={k})...\")\n",
    "        \n",
    "        # Step 2: Retrieve documents\n",
    "        retrieved_data = retriever.retrieve_with_sources(question, k=k)\n",
    "        \n",
    "        # üöÄ STARTUP BOOSTER: Enhance results for startup-related queries\n",
    "        startup_boost_applied = False\n",
    "        if any(keyword in question.lower() for keyword in ['startup', 'company', 'venture', 'business']):\n",
    "            print(\"   üöÄ Boosting startups file for this query...\")\n",
    "            # Get additional results focusing on startups\n",
    "            startup_data = retriever.retrieve_with_sources(question + \" startups companies\", k=2)\n",
    "            \n",
    "            # Filter to only include startups file and avoid duplicates\n",
    "            startup_items = []\n",
    "            for item in startup_data:\n",
    "                if 'startups_processed.txt' in item['source_file']:\n",
    "                    # Check if this content is already in retrieved_data\n",
    "                    is_duplicate = any(\n",
    "                        item['content'] == existing['content'] \n",
    "                        for existing in retrieved_data\n",
    "                    )\n",
    "                    if not is_duplicate:\n",
    "                        startup_items.append(item)\n",
    "            \n",
    "            # Add startup items to the beginning of results\n",
    "            if startup_items:\n",
    "                retrieved_data = startup_items + retrieved_data\n",
    "                retrieved_data = retrieved_data[:k]  # Keep original k limit\n",
    "                startup_boost_applied = True\n",
    "                print(f\"   ‚úÖ Added {len(startup_items)} startup-specific results\")\n",
    "        \n",
    "        print(f\"   ‚úÖ Found {len(retrieved_data)} relevant chunks\")\n",
    "        \n",
    "        # Step 3: Format context with human-readable source names\n",
    "        context = \"\\n\\n\".join([\n",
    "            f\"Source: {format_source_name(item['source_file'])} | Type: {item['doc_type']}\\nContent: {item['content']}\"\n",
    "            for item in retrieved_data\n",
    "        ])\n",
    "        \n",
    "        # Step 4: Build smart prompt\n",
    "        print(\"2. üìù Building prompt...\")\n",
    "        prompt = build_smart_prompt(question, context)\n",
    "        \n",
    "        # Step 5: Generate answer using LLM\n",
    "        print(\"3. ü§ñ Generating answer with LLM...\")\n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=500,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        # Step 6: Prepare results\n",
    "        result = {\n",
    "            'query_id': query_id,\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': retrieved_data,\n",
    "            'retrieved_chunks': len(retrieved_data),\n",
    "            'source_count_used': k,\n",
    "            'startup_boost_applied': startup_boost_applied,  # üÜï Track if booster was used\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_used': 'llama-3.1-8b-instant'\n",
    "        }\n",
    "        \n",
    "        # Display results\n",
    "        print(\"4. üìä RESULTS:\")\n",
    "        print(f\"ANSWER: {answer}\")\n",
    "        print(f\"SOURCES: {len(retrieved_data)} documents (k={k})\")\n",
    "        if startup_boost_applied:\n",
    "            print(\"   üöÄ Startup boost was applied to this query\")\n",
    "        for i, item in enumerate(retrieved_data):\n",
    "            readable_name = format_source_name(item['source_file'])\n",
    "            boost_indicator = \"üöÄ \" if 'startups_processed.txt' in item['source_file'] and startup_boost_applied else \"\"\n",
    "            print(f\"   {i+1}. {boost_indicator}{readable_name} (Score: {item['similarity_score']:.3f})\")\n",
    "        \n",
    "        print(\"‚úÖ Query completed successfully!\\n\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pipeline error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"../../07_testsdemo/test_outputs/demo_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Test all queries\n",
    "print(\"üöÄ TESTING ALL USER QUERIES WITH DYNAMIC SOURCE COUNT & STARTUP BOOSTER\")\n",
    "print(\"Note: Predictive section not yet integrated - focusing on RAG performance\\n\")\n",
    "\n",
    "all_results = []\n",
    "successful_queries = 0\n",
    "\n",
    "for query_id, question in USER_QUERIES.items():\n",
    "    result = test_complete_pipeline(question, query_id)\n",
    "    if result:\n",
    "        all_results.append(result)\n",
    "        successful_queries += 1\n",
    "        \n",
    "        # Save individual query result\n",
    "        individual_file = f\"{output_dir}/user_query_{query_id}_{datetime.now().strftime('%Y%m%d_%H%M')}.json\"\n",
    "        with open(individual_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Save consolidated results\n",
    "if all_results:\n",
    "    consolidated_file = f\"{output_dir}/all_user_queries_with_startup_boost_{datetime.now().strftime('%Y%m%d_%H%M')}.json\"\n",
    "    with open(consolidated_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"üéâ TESTING COMPLETE!\")\n",
    "    print(f\"‚úÖ Successful queries: {successful_queries}/{len(USER_QUERIES)}\")\n",
    "    print(f\"üìÅ Individual results saved to: {output_dir}/\")\n",
    "    print(f\"üìä Consolidated results: {consolidated_file}\")\n",
    "    \n",
    "    # Summary with source count and boost info\n",
    "    print(\"\\nüìà QUERY PERFORMANCE SUMMARY:\")\n",
    "    for result in all_results:\n",
    "        boost_info = \" üöÄ\" if result['startup_boost_applied'] else \"\"\n",
    "        print(f\"  Q{result['query_id']}: k={result['source_count_used']}, {len(result['sources'])} sources{boost_info}, {len(result['answer'])} chars\")\n",
    "        \n",
    "else:\n",
    "    print(\"üí• No queries completed successfully\")\n",
    "\n",
    "print(f\"\\nüìù Note: Predictive model integration pending - currently testing RAG pipeline only\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
